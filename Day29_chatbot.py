# -*- coding: utf-8 -*-
"""Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C4yoeevw6JtkFqjuBdhqD-MAZIvrr8VF
"""

!pip install transformers

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline

# Load a better conversational model
model_name = "facebook/blenderbot-400M-distill"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Chatbot function
def chat():
    print("Chatbot: Hello! Type 'exit' to end the conversation.")
    chat_history = []  # Maintain history for context

    while True:
        user_input = input("You: ")
        if user_input.lower() == "exit":
            print("Chatbot: Goodbye!")
            break

        # Append user input to history
        chat_history.append(user_input)
        input_text = " ".join(chat_history[-5:])  # Keep last 5 exchanges for context

        # Generate response
        inputs = tokenizer(input_text, return_tensors="pt")
        response_ids = model.generate(**inputs)
        response_text = tokenizer.decode(response_ids[0], skip_special_tokens=True)

        print(f"Chatbot: {response_text}")

        # Append bot response to history
        chat_history.append(response_text)

# Run the chatbot
if __name__ == "__main__":
    chat()

